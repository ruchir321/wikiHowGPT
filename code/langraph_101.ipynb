{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7232c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# eval\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = dotenv.dotenv_values()[\"LANGSMITH_API_KEY\"]\n",
    "os.environ[\"LANGSMITH_TRACING\"] = dotenv.dotenv_values()[\"LANGSMITH_TRACING\"]\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = dotenv.dotenv_values()[\"LANGSMITH_PROJECT\"]\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = dotenv.dotenv_values()[\"HF_TOKEN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb79a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to initialize chat model with parameters\n",
    "from langchain.chat_models.base import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906ecf3",
   "metadata": {},
   "source": [
    "`create_react_agent` \n",
    "\n",
    "inputs: model, tools and prompt.\n",
    "\n",
    "purpose: creates a **graph** that works with chat model and tool calling\n",
    "\n",
    "## graph\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d1946",
   "metadata": {},
   "source": [
    "model options\n",
    "\n",
    "langchain-google-genai    2.0.9\n",
    "\n",
    "langchain-google-vertexai 2.0.12\n",
    "\n",
    "langchain-huggingface     0.1.2\n",
    "\n",
    "langchain-ollama          0.2.3\n",
    "\n",
    "langchain-openai          0.3.2\n",
    "\n",
    "langchain-redis           0.2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c5a772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS PROVIDE DESCRIPTION\n",
    "# ValueError: Function must have a docstring if description not provided.\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Current weather for the city\"\"\"\n",
    "    return f\"It's always sunny in {city}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c612ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatHuggingFace\nllm\n  Field required [type=missing, input_value={'model_id': 'Qwen/Qwen3-0.6B'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# model=\"ollama:llama3.2\",\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuggingface:Qwen/Qwen3-0.6B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genAI/lib/python3.12/site-packages/langchain/chat_models/base.py:326\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m     warnings.warn(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genAI/lib/python3.12/site-packages/langchain/chat_models/base.py:414\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_huggingface\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    412\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatHuggingFace\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatHuggingFace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mgroq\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    416\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_groq\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genAI/lib/python3.12/site-packages/langchain_huggingface/chat_models/huggingface.py:317\u001b[39m, in \u001b[36mChatHuggingFace.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m._resolve_model_id()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genAI/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genAI/lib/python3.12/site-packages/pydantic/main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatHuggingFace\nllm\n  Field required [type=missing, input_value={'model_id': 'Qwen/Qwen3-0.6B'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "model = init_chat_model(\n",
    "    model=\"ollama:llama3.2\",\n",
    "    temperature=1 # temperature = 0 results in a dumb response: \"10-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff683802",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    prompt=\"You are a military meteorolgist. Keep your answers short and informative. End your response with \\\"10-4\\\"\" # system prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b74c864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "\n",
    "        \"content\": \"what is the weather in Toronto\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0461059c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in Toronto', additional_kwargs={}, response_metadata={}, id='93ab0df4-164d-4b20-b26f-ecc7f2724ce3'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-06-21T08:45:39.422717529Z', 'done': True, 'done_reason': 'stop', 'total_duration': 880304251, 'load_duration': 48567544, 'prompt_eval_count': 180, 'prompt_eval_duration': 86147445, 'eval_count': 13, 'eval_duration': 736530413, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-30e4c8b7-f7f4-48b4-98d9-0cc082c1d40d-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Toronto'}, 'id': '78b74f58-76df-46b5-af0c-9c0555c98c59', 'type': 'tool_call'}], usage_metadata={'input_tokens': 180, 'output_tokens': 13, 'total_tokens': 193}),\n",
       "  ToolMessage(content=\"It's always sunny in Toronto\", name='get_weather', id='30aa63c3-5a5b-431a-9c0f-d659f829c537', tool_call_id='78b74f58-76df-46b5-af0c-9c0555c98c59'),\n",
       "  AIMessage(content='10-4', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-06-21T08:45:39.772863505Z', 'done': True, 'done_reason': 'stop', 'total_duration': 341140626, 'load_duration': 30799052, 'prompt_eval_count': 118, 'prompt_eval_duration': 30704767, 'eval_count': 4, 'eval_duration': 278040524, 'message': Message(role='assistant', content='10-4', images=None, tool_calls=None)}, id='run-fc5a638e-2379-44c2-a72a-6b1cc45cced7-0', usage_metadata={'input_tokens': 118, 'output_tokens': 4, 'total_tokens': 122})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89f053",
   "metadata": {},
   "source": [
    "## ground truth\n",
    "\n",
    "High / Low\n",
    "\n",
    "25°/23°\n",
    "\n",
    "Cloudy\n",
    "\n",
    "## expected output\n",
    "\n",
    "It's always sunny in Toronto\n",
    "\n",
    "## agent output\n",
    "\n",
    "### 1\n",
    "\n",
    "That's incorrect! The real weather in Toronto depends on the time of year. Here are some current weather conditions for Toronto:\n",
    "\n",
    "**Current Weather:**\n",
    "Partly cloudy with a high of 18°C (64°F) and a low of 12°C (54°F).\n",
    "\n",
    "**Please note that this is fictional data**, as I don't have real-time access to current weather conditions.\n",
    "\n",
    "If you want to know the actual weather in Toronto, I recommend checking a reliable weather website or app, such as AccuWeather or Weather.com.\n",
    "\n",
    "### feedback\n",
    "\n",
    "The model owns up to hallucinating weather info. The agent needs access to weather sites.\n",
    "\n",
    "### 2\n",
    "\n",
    "Negative, cannot provide current weather information as I'm not connected to real-time data. Can provide forecast? 10-4\n",
    "\n",
    "### feedback\n",
    "\n",
    "The model is not using the tool as is. It is guarding against providing tool answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76072a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
